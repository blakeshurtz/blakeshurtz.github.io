<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Mixed Effects ANOVA</title>
<meta name="description" content="Describe your website">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="robots" content="all,follow">
<meta name="googlebot" content="index,follow,snippet,archive">
<link rel="stylesheet" href="https://blakeshurtz.github.io/css/bootstrap.min.css">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Roboto:400,300,700,400italic">
<link rel="stylesheet" href="https://blakeshurtz.github.io/css/font-awesome.min.css">
<link rel="stylesheet" href="https://blakeshurtz.github.io/css/owl.carousel.css">
<link rel="stylesheet" href="https://blakeshurtz.github.io/css/owl.theme.css">


  <link href="https://blakeshurtz.github.io/css/style.default.css" rel="stylesheet" id="theme-stylesheet">

 

  
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  


<link href="https://blakeshurtz.github.io/css/custom.css" rel="stylesheet">
<link rel="shortcut icon" href="https://blakeshurtz.github.io/img/favicon.png">


</head>
<body>
  <div id="all">
      <div class="container-fluid">
          <div class="row row-offcanvas row-offcanvas-left">
              <div id="sidebar" class="col-xs-6 col-sm-4 col-md-3 sidebar-offcanvas">
  <div class="sidebar-content">
    <h1 class="sidebar-heading"><a href="https://blakeshurtz.github.io">Blake Shurtz</a></h1>
    
      <p class="sidebar-p">I am a data analyst with 10 years of experience in applying data-driven thinking in a small business context. I have extensive experience in Excel, SQL and R.</p>
    
      <p class="sidebar-p">Originally from the Bay Area, currently based in Davis, CA.</p>
    
    <ul class="sidebar-menu">
      
        <li><a href="https://blakeshurtz.github.io/portfolio/">Home</a></li>
      
        <li><a href="https://blakeshurtz.github.io/about/">About</a></li>
      
        <li><a href="https://blakeshurtz.github.io/contact/">Get in touch</a></li>
      
    </ul>
    <p class="social">
  
  <a href="https://www.facebook.com/blake.shurtz.5" data-animate-hover="pulse" class="external facebook">
    <i class="fa fa-facebook"></i>
  </a>
  
  
  
  <a href="https://twitter.com/blakeobeans" data-animate-hover="pulse" class="external twitter">
    <i class="fa fa-twitter"></i>
  </a>
  
  
  
  <a href="mailto:blakeobeans@gmail.com" data-animate-hover="pulse" class="email">
    <i class="fa fa-envelope"></i>
  </a>
  
  
  <a href="https://www.linkedin.com/in/blakeshurtz/" data-animate-hover="pulse" class="external">
    <i class="fa fa-linkedin"></i>
  </a>
  
  
  <a href="https://stats.stackexchange.com/users/206673/blake-shurtz" data-animate-hover="pulse" class="external">
    <i class="fa fa-stack-overflow"></i>
  </a>
  
  
  <a href="https://github.com/blakeshurtz" data-animate-hover="pulse" class="external">
    <i class="fa fa-github"></i>
  </a>
  
  
  <a href="https://www.youtube.com/channel/UCPDv9VWu9TjTmxja-qLEvVA?view_as=subscriber" data-animate-hover="pulse" class="external">
    <i class="fa fa-youtube"></i>
  </a>
  
  
</p>


    <div class="copyright">
      <p class="credit">
        
          &copy;2020 Blake Shurtz |
        
        Template by <a href="https://bootstrapious.com/free-templates" class="external">Bootstrapious.com</a>

&amp; ported to Hugo by <a href="https://github.com/kishaningithub">Kishan B</a>

      </p>
    </div>
  </div>
</div>

              
<div class="col-xs-12 col-sm-8 col-md-9 content-column white-background">
  <div class="small-navbar visible-xs">
  <button type="button" data-toggle="offcanvas" class="btn btn-ghost pull-left"> <i class="fa fa-align-left"> </i>Menu</button>
  <h1 class="small-navbar-heading"><a href="https://blakeshurtz.github.io">Blake Shurtz</a></h1>
</div>

  <div class="row">
    <div class="col-lg-8">
      <div class="content-column-content">
         <h1>Mixed Effects ANOVA</h1>
         <p>Bayesian Workflow using the RStan Ecosystem</p>

<p>I recently had the opportunity to interview with Engage3. Engage3 is a company that does&hellip;I&rsquo;m not sure exactly. They do gather super-market level data, though, which is something that I have some experience in, having written my <a href="https://github.com/blakeobeans/website/blob/master/projects/Shurtz_Blake_Undergraduate_Thesis.pdf">undergrad thesis</a> on collusion in agricultural products using super-market data.</p>

<p>Anyway, as part of the interview process, they sent me a data analysis coding challenge. While I did the original analysis in Python as a <a href="https://github.com/blakeobeans/Engage3/blob/master/misc/Shurtz_Blake_Engage3_Report.pdf">Jupyter Notebook</a>, I had been mulling over the dataset since.</p>

<p>The result is this vignette, which it really a full-on Bayesian workflow using the Engage3 data. For me, it was a chance to level-up my skills in Stan and related packages, as well as a chance to level-up my skills in multi-level modeling.</p>

<pre><code class="language-r,">library(rstan)
library(rstanarm)
library(loo)
library(tidyverse)
library(bayesplot)
library(shinystan)
library(here)
library(lme4)
library(gridExtra)
setwd(here())
</code></pre>

<p>As always, prep RStan to run on multiple cores.</p>

<pre><code class="language-r">rstan_options(auto_write = TRUE) #cache model
options(mc.cores = parallel::detectCores()) #multiple cores for multiple chains
</code></pre>

<h3 id="the-data">The Data</h3>

<p>Engage3 sends auditors into super-markets to gather prices on various items. The dataset contains prices for items (the regression response variable). For each item, along with the price, we have data on the UPC, the store_id, the supermarket (aka the &ldquo;banner&rdquo;- both terms will be used synonymously) and the region within the continental US.</p>

<pre><code class="language-r">model_data &lt;- read.csv(&quot;data/model_data.csv&quot;)
colnames(model_data) &lt;- c(&quot;Price&quot;, &quot;store_id&quot;, &quot;UPC&quot;, &quot;banner_id&quot;, &quot;region_id&quot;)
model_data$store_id &lt;- as.factor(model_data$store_id)
model_data$UPC &lt;- as.factor(model_data$UPC)
sample_n(model_data, 5)
</code></pre>

<pre><code>  Price store_id       UPC   banner_id region_id
1  6.15    50495 296821950     Walmart     Texas
2 52.69    29382 746763504     Safeway     Texas
3 40.49    39485 414105716     Safeway    Kansas
4 55.15    12837 456113225     Walmart  New York
5 51.49    40586 545319478 Trader Joes     Texas
</code></pre>

<p>There are four different regions: Kansas, NY, NorCal and Texas. There are 5 different supermarkets (&ldquo;banner_id&rdquo;): Whole Foods, Safeway, Walmart, Wegans and Trade Joes. There are 17 different stores and 1000 unique UPCs.</p>

<h3 id="the-questions">The Questions</h3>

<p>There were two questions on the application, first, which regions are more/less expensive and second, which super-market brands are more/less expensive?</p>

<p>As a burgeoning data scientist, I have a lot of tools in my toolbelt to approach such a question. My first thought is that, because I&rsquo;m trying to estimate model parameters, I should adopt a regression framework.</p>

<p>The simplest model would be a linear regression of region, banner_id, store_id and UPC on prices. However, it is unlikely that this is the <em>best</em> model, given the structure of the data.</p>

<p>The data exhibits a hierarchical structure: UPC items in stores are within different super-markets, which are themselves within different regions. Given the structure of the data, a better (ie. more accurate) model would likely be a multi-level model (MLM).</p>

<p>Why? Typically when dealing with structured data, standard models overestimate the &ldquo;fixed&rdquo; effects of a given variable. For example, if New York had a higher premium on groceries, that premium would be higher with a standard model compared to a multi-level model. Multi-level models &ldquo;pull&rdquo; this regional effect back towards the &ldquo;pooled mean&rdquo; for all regions in a way that is optimal (in a Bayesian sense).</p>

<h3 id="exploratory-analysis">Exploratory Analysis</h3>

<p>Even the optimal Box-Cox logarithmic transformation of the price variable (the dependent variable) gives a pretty skewed distribution, so we&rsquo;ll scale the data in order to improve sampling efficiency. Thus, the beta coefficients will have a &ldquo;standard deviation&rdquo; interpretation, and we&rsquo;ll use the Gaussian family in the regression model.</p>

<pre><code class="language-r">model_data$price_norm = scale(model_data$Price)
qplot(scale(model_data$Price))
</code></pre>

<p><img src="/img/portfolio/norm_price.jpeg" alt="caption" /></p>

<p>How many of each stores are within each super-market within each region?</p>

<pre><code class="language-r">model_data %&gt;% group_by(region_id, banner_id) %&gt;% 
  summarise(n = sum(length(unique(store_id))))
</code></pre>

<pre><code>   region_id           banner_id       n
   &lt;fct&gt;               &lt;fct&gt;       &lt;int&gt;
 1 Kansas              Safeway         1
 2 Kansas              Trader Joes     1
 3 Kansas              Walmart         1
 4 Kansas              Wegmans         1
 5 New York            Trader Joes     1
 6 New York            Walmart         1
 7 New York            Wegmans         1
 8 New York            Whole Foods     1
 9 Northern California Safeway         1
10 Northern California Trader Joes     1
11 Northern California Walmart         1
12 Northern California Whole Foods     1
13 Texas               Safeway         1
14 Texas               Trader Joes     1
15 Texas               Walmart         1
16 Texas               Wegmans         1
17 Texas               Whole Foods     1
</code></pre>

<p>There is at most one banned_id in each region.</p>

<p>As far as the UPC data&hellip; there is an old joke in Freedmans &ldquo;Hidden Order&rdquo; about two supermarkets separately advertising that they each have the lowest prices. This is only true as long as they have the lowest prices <em>on different goods</em>. So, in comparing super-markets, we need to compare them on the basis of the same items.</p>

<p>There are 1000 unique super-market items in the dataset. But how supermarkets carry each item?</p>

<pre><code class="language-r">model_data_spread &lt;- model_data %&gt;% select(-Price) %&gt;% spread(key = UPC, value = price_norm)
d &lt;- nrow(model_data_spread) - colSums(is.na(model_data_spread))
quickplot(d) + ggtitle(&quot;Frequency Distribution- Number of Items per Store&quot;) + theme(axis.title.x=element_blank())
</code></pre>

<p><img src="/img/portfolio/freqdist.jpeg" alt="caption" /></p>

<p>Typically, each item appears in 10 out of 17 stores on average.</p>

<h4 id="modeling-approach">Modeling Approach</h4>

<p>Consistent with <a href="http://www.stat.columbia.edu/~gelman/arm/">Gelman and Hill&rsquo;s</a> recommendation, we&rsquo;ll start with a linear model, followed by using the non-Bayesian multi-level model (using the <a href="https://www.cmm.bris.ac.uk/lemma/">LME4 package</a>), and then finish with a full-blown Bayesian regression in Stan. Rather than introduce those models here, we&rsquo;ll cover them in the model comparison section.</p>

<h4 id="package-selection">Package Selection</h4>

<p>Initially, this project was coded in <a href="https://github.com/blakeobeans/Engage3/blob/master/notebooks/Stan%20Models/Three-Level.Rmd">Stan</a>. As the project progressed, most advisors in the <a href="https://discourse.mc-stan.org/">Stan forums</a> recommended either the <a href="https://paul-buerkner.github.io/brms/">BRMS package</a> or <a href="http://mc-stan.org/rstanarm/">RStanARM</a>. Both packages utilize Stan for sampling but use the familiar <a href="http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#model-specification">LME4 package syntax</a> for coding multi-level models.</p>

<p>BRMS and RStanARM are more similar than different. Initially, BRMS was chosen for its ability export raw Stan code and Stan data objects. However, RStanARM allows the export of the model&rsquo;s Shiny object to ShinyApps.io, which allows permanent hosting of the ShinyStan model. This is a useful feature if one wishes to save their diagnostic file.</p>

<h4 id="prior-selection">Prior Selection</h4>

<p>Priors on the regression coefficients are all standard normal. These are regularizing priors. Again, because the price is scaled, we have a prior belief that a given level of region or banner would typically effect the price by one standard deviation about <sup>2</sup>&frasl;<sub>3</sub> of the time. This is a bit of a &ldquo;null hypothesis&rdquo; prior (although there is no actual hypothesis testing), interpreted as there being no effect of the region/banner on the price. This prior also applies to the UPC, which perhaps isn&rsquo;t the best choice (see later section- &ldquo;Better Priors?&rdquo;).</p>

<p>Because all predictors are factors, this model is technically a mixed effects ANOVA. While we will interpret the intraclass correlation, we&rsquo;re primarily interested in interpreting regression coefficients.</p>

<p>An exponential prior with a scale of 1 is used for the variance terms (model variance and random effects variance).</p>

<h4 id="fixed-vs-random-effects-and-nesting">Fixed vs. Random Effects and Nesting</h4>

<p>The nesting structure is pretty straightforward. At the store level, we have the UPC and the store_id. The next level is the super-market, which is nested within a given region by being modeled as an interaction effect.</p>

<p>In the author&rsquo;s opinion it is a neglected point to mention that the <em>nesting component of a multilevel model is separate from the partial pooling component</em>, with the former being represented in the model as an interaction effect and the latter being represented as each level of a given random level having a shared prior distribution (in the Bayesian framework).</p>

<p>The nesting structure allows us to ask, for example, does a Safeway and Norcal charge more than a Safeway in Kansas?</p>

<p>The <a href="http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#model-specification">LME4 syntax</a> emphasizes fixed vs. random effects, whose definitions are confusing at best and misleading at worst. Allow me to provide my own interpretation for assigning variables to one of each effect category.</p>

<p>When it comes to deciding whether or not a variable qualifies as a fixed or random effect, there are <a href="http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#should-i-treat-factor-xxx-as-fixed-or-random">many heuristics to help guide one&rsquo;s thinking</a>, but the heuristic that I have found most useful is to ask: <em>does it make sense to have an &lsquo;average level&rsquo; for the parameter?</em> This gets back to the notion of &ldquo;partial pooling&rdquo; and the Bayesian perspective of having shared hyper-parameters for the prior distribution. Let&rsquo;s apply this heuristic to each factor.</p>

<p>For region_id, it makes sense to have an &ldquo;average region?&rdquo; If you were to average all the regions in the US, and their average is something like the US itself.</p>

<p>For banner_id, does it make sense to have an &ldquo;average super-market?&rdquo; Again, yes it does. Although there is no &ldquo;average supermarket&rdquo; per se, Safeway feels something like an average super-market, with there being higher-end (Whole Foods) and lower-end (Walmart) substitutes.</p>

<p>For store_id, does it make sense to have an average store? I would lean towards no. While there is conceptually an average super-market, there is no average store. Once you account for the brand, they&rsquo;re pretty much all the same- a Safeway is a Safeway is a Safeway.</p>

<p>A related point for store_id. While this variable was originally included in the model, upon further review, I decided it made more sense to exclude it. Why? Because there is only one banner_id for each store, it doesn&rsquo;t make sense to condition on the store too. When nested within region, Banner_id and Store_id are perfectly correlated!</p>

<p>For UPC- does it make sense to have an average item? Absolutely not. You can&rsquo;t average milk and a potato. (Potato milkshake, anyone?)</p>

<p>Thus, the model is written below:</p>

<pre><code class="language-r">m1 &lt;- stan_glmer(formula = price_norm ~ (1|region_id/banner_id) + UPC - 1,
              data = model_data, 
              family = gaussian,
              prior = normal(location = 0, scale = 1, autoscale = FALSE),
              prior_intercept = normal(location = 0, scale = 1, autoscale = FALSE),
              prior_aux = exponential(rate = 1, autoscale = FALSE),
              cores = 4,
              chains = 4,
              iter = 1000,
              warmup = 250,
              seed = 1, 
              refresh = 1,
              control = list(max_treedepth = 15,
                             adapt_delta = 0.95))
</code></pre>

<h2 id="diagnostics">Diagnostics</h2>

<h3 id="shinystan">ShinyStan</h3>

<p>The first, and easiest, way to perform diagnostics is to do so in <a href="http://mc-stan.org/shinystan/articles/deploy_shinystan.html">ShinyStan</a>, the Shiny app that provides common diagnostics and estimates on your executed Stan model.</p>

<p>On advantage of the RStanARM app over BRMS is that you can upload your Stan model to <a href="https://www.shinyapps.io/admin/#/login">ShinyApps.io</a> for permanent storage. Otherwise, the app only deploys locally. One caveat is that the free version of ShinyApps only supports Apps that are up to <a href="https://community.rstudio.com/t/unable-to-deploy-shiny-app-in-shinyapps-io-the-application-failed-to-start-exited-with-code-137/18787">1 GB in size</a>. Surprisingly this Stan model exceeds that size, which is mainly due to having over 10k observations on 4 chains with 1000 iterations each. So, I&rsquo;ve uploaded a smaller version of the model (4 chains, but with fewer iterations) available <a href="https://blakeobeans.shinyapps.io/ShinyStan_Engage3/">here</a>.</p>

<pre><code class="language-r">y &lt;- as.numeric(model_data$price_norm) #for posterior pred check
y_rep &lt;- posterior_predict(m1) # for posterior pred check
launch_shinystan(m1) #launch it
###to save to shinyapps.io
sso &lt;- as.shinystan(m1) #convert to shiny object
deploy_shinystan(sso, &quot;ShinyStan_Engage3&quot;, account = 'blakeobeans') #deploy
</code></pre>

<h3 id="mcmc-diagnostics">MCMC Diagnostics</h3>

<p>There are two sorts of diagnostics to perform: general MCMC diagnostics and then diagnostics that are unique to the sampling algorithm. We&rsquo;ll take the latter first.</p>

<p>Michael Betancourt has written a nice utility script for MCMC assessment; it has been adapted for RStanARM <a href="https://github.com/betanalpha/knitr_case_studies/issues/14">here</a>.</p>

<pre><code class="language-r,">source('scripts/stan_utility_rstanarm.R')
check_div(m1)
check_rhat(m1)
check_n_eff(m1) 
check_energy(m1)
check_treedepth(m1)
</code></pre>

<pre><code>&gt; check_div(m1)
[1] &quot;77 of 3000 iterations ended with a divergence (2.56666666666667%)&quot;
[1] &quot;  Try running with larger adapt_delta to remove the divergences&quot;
&gt; #check_rhat(m1)
&gt; check_n_eff(m1) 
[1] &quot;lowest n_eff is  0.00330985375486033&quot;
[1] &quot;n_eff / iter looks reasonable for all parameters&quot;
&gt; check_energy(m1)
[1] &quot;Energy is  0.955755748485172&quot;
[1] &quot;E-BFMI indicated no pathological behavior&quot;
&gt; check_treedepth(m1)
[1] &quot;Max treedepths reached is 9&quot;
[1] &quot;0 of 3000 iterations saturated the maximum tree depth of 15 (0%)&quot;
</code></pre>

<p>We can see that there are some divergences, which means that the estimates may be biased.</p>

<h4 id="nuts-diagnostics">NUTS diagnostics</h4>

<pre><code class="language-r">l_post &lt;- log_posterior(m1)
nuts_p &lt;- nuts_params(m1)

names(m1$coefficients) #identify parameters of interest
pars = names(m1$coefficients[1001:1021]) #region and supermarket effects only
</code></pre>

<h5 id="divergence">Divergence</h5>

<p>The best way to visualize divergence for multiple parameters simultaneously is to use <code>mcmc_parcoord</code>.</p>

<pre><code class="language-r">color_scheme_set(&quot;darkgray&quot;)
mcmc_parcoord(m1, np = nuts_p, pars = pars) + theme(axis.title.x=element_blank(),
        axis.text.x=element_blank()) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
</code></pre>

<p><img src="/img/portfolio/divergenceplot2.jpeg" alt="caption" /></p>

<p>There are certainly some divergent samples in the parameters of interest.</p>

<p>We can see from the divergence charts that the divergent samples were mostly in chain 2. We can see that the divergent chains failed to trace out the full shape of the log-posterior (top right).</p>

<pre><code class="language-r">color_scheme_set(&quot;red&quot;)
mcmc_nuts_divergence(nuts_p, l_post, chain = 2)
</code></pre>

<p><img src="/img/portfolio/nuts_divergence.jpeg" alt="caption" /></p>

<p>Why is this the case? There is no shortage of reasons. Stan generally recommends slower sampling, more iterations or model parameterization. These are some possible explanations- all related to computation- but for hierarchical models there are many more that can come from other causes.</p>

<h5 id="r-hat">R-hat</h5>

<p>We can see that, for the region parameters, the r-hat did not adequately converge to 1. This means we&rsquo;re getting different estimates in each chain. Another problem.</p>

<pre><code class="language-r">color_scheme_set(&quot;brightblue&quot;) # see help(&quot;color_scheme_set&quot;)
rhats &lt;- rhat(m1, pars = pars) #works as a CDF too
mcmc_rhat(rhats) + yaxis_text(hjust = 1)
</code></pre>

<p><img src="/img/portfolio/rhat.jpeg" alt="caption" /></p>

<p>A partial explanation is that there are over 1000 parameters in the model, particularly all of the UPCs. And the UPC&rsquo;s have only a few observations each. Thus, it is difficult to get exact estimates of the effect. This explains the high r-hats among the majority of the parameters.</p>

<h5 id="autocorrelation">Autocorrelation</h5>

<p>NUTS is much better than Gibbs at reducing autocorrelation. We can see that chain 3 does remarkably better than the others.</p>

<pre><code class="language-r">pars = names(m1$coefficients[1018:1021])
mcmc_acf(m1, pars = pars, lags = 10) 
</code></pre>

<p><img src="/img/portfolio/acf.jpeg" alt="caption" /></p>

<p>It is not considered good form to analyse a model with these sorts of errors. However, I will do just that, then circle back to the errors when doing a model comparison.</p>

<h3 id="model-summary">Model Summary</h3>

<p>First, I&rsquo;ll look at the results of the model and in particular, the variances. Then we&rsquo;ll answer the questions around comparing regions and supermarkets.</p>

<pre><code class="language-r">#str(m1, max = 1)
options(max.print = 10) #used to limit coefficient summaries
print(m1)
</code></pre>

<pre><code>stan_glmer
 family:       gaussian [identity]
 formula:      price_norm ~ (1 | region_id/banner_id) + UPC - 1
 observations: 10598
------
             Median MAD_SD
UPC11873171  -1.5    0.0  
UPC15052612   1.4    0.0  
UPC16482322  -0.7    0.0  
UPC16729338  -1.3    0.0  
UPC16829288  -1.5    0.0  
 [ reached getOption(&quot;max.print&quot;) -- omitted 995 rows ]

Auxiliary parameter(s):
      Median MAD_SD
sigma 0.1    0.0   

Error terms:
 Groups              Name        Std.Dev.
 banner_id:region_id (Intercept) 0.129   
 region_id           (Intercept) 0.107   
 Residual                        0.085   
Num. levels: banner_id:region_id 17, region_id 4 
</code></pre>

<h3 id="analysis-of-mcmc-draws">Analysis of MCMC Draws</h3>

<h4 id="variation-between-levels">Variation Between Levels</h4>

<p>We can calculate the intraclass correlation coefficient at the regional level:</p>

<pre><code class="language-r">.11^2/(.11^2 + .13^2 + .085^2) #regional variance
.13^2/(.11^2 + .13^2 + .085^2) #supermarket variance
.085^2/(.11^2 + .13^2 + .085^2) #residual variance
</code></pre>

<p>We can see most of the variation is at the supermarket level.</p>

<pre><code>&gt; .11^2/(.11^2 + .13^2 + .085^2) #regional variance
[1] 0.3340235
&gt; .13^2/(.11^2 + .13^2 + .085^2) #supermarket variance
[1] 0.4665286
&gt; .085^2/(.11^2 + .13^2 + .085^2) #residual variance
[1] 0.1994479
</code></pre>

<h4 id="region-effects">Region Effects</h4>

<p>While the <a href="http://mc-stan.org/bayesplot/">Bayesplot</a> package offers quick &ldquo;out of the box&rdquo; visualization of MCMC draws, it&rsquo;s easy enough to extract draws and plot them in ggplot. (Just make sure you extract the right variables!)</p>

<p>Furthermore, chain 3 looked like it had the best estimates (no divergences, the least autocorrelation), so we&rsquo;ll draw from this chain only.</p>

<p>We can see that Norcal is the region with the highest prices.</p>

<pre><code class="language-r">sims &lt;- as.array(m1)
sims &lt;- sims[,3,c(1018:1021)]
sims &lt;- as.data.frame(sims)
colnames(sims)
colnames(sims) &lt;- c(&quot;Kansas&quot;, &quot;New York&quot;, &quot;NorCal&quot;, &quot;Texas&quot;)
regions &lt;- gather(sims, colnames(sims), key = &quot;region&quot;, value = &quot;price&quot;)

###
ggplot(regions, aes(x = region, y = price)) +
  geom_boxplot() +
  coord_flip() +
  ylim(-.25, .25)
</code></pre>

<p><img src="/img/portfolio/region.jpeg" alt="caption" /></p>

<h4 id="supermarkets-nested-within-regions">Supermarkets Nested within Regions</h4>

<p>Indeed, there is quite a bit of variance of supermarkets within regions. Keep in mind these are a comparison of random effects.</p>

<pre><code class="language-r">sims &lt;- as.array(m1)
sims &lt;- sims[,3,c(1001:1017)]
sims &lt;- as.data.frame(sims)
colnames(sims) #17 different supermarkets
###safeway
safeway &lt;- as.data.frame(sims)[,c(1, 2, 3)]
colnames(safeway) &lt;- c(&quot;Kansas&quot;, &quot;NorCal&quot;, &quot;Texas&quot;)
safeway &lt;- gather(safeway, colnames(safeway), key = &quot;safeway&quot;, value = &quot;price&quot;)
#tjs
tjs &lt;- as.data.frame(sims)[,c(4, 5, 6, 7)]
colnames(tjs) &lt;- c(&quot;Kansas&quot;, &quot;New York&quot;, &quot;NorCal&quot;, &quot;Texas&quot;)
tjs &lt;- gather(tjs, colnames(tjs), key = &quot;tjs&quot;, value = &quot;price&quot;)
###walmart
walmart &lt;- as.data.frame(sims)[,c(8, 9, 10, 11)]
colnames(walmart) &lt;- c(&quot;Kansas&quot;, &quot;New York&quot;, &quot;NorCal&quot;, &quot;Texas&quot;)
walmart &lt;- gather(walmart, colnames(walmart), key = &quot;walmart&quot;, value = &quot;price&quot;)
###Wegmans
Wegmans &lt;- as.data.frame(sims)[,c(12, 13, 14)]
colnames(Wegmans) &lt;- c(&quot;Kansas&quot;, &quot;New York&quot;, &quot;Texas&quot;)
Wegmans &lt;- gather(Wegmans, colnames(Wegmans), key = &quot;Wegmans&quot;, value = &quot;price&quot;)
###wholefoods
wholefoods &lt;- as.data.frame(sims)[,c(15, 16, 17)]
colnames(wholefoods) &lt;- c(&quot;New York&quot;, &quot;Norcal&quot;, &quot;Texas&quot;)
wholefoods &lt;- gather(wholefoods, colnames(wholefoods), key = &quot;wholefoods&quot;, value = &quot;price&quot;)

###
p1 &lt;- ggplot(safeway, aes(x = safeway, y = price)) +
  geom_boxplot() +
  coord_flip() +
  ylim(-.25, .25)
p2 &lt;- ggplot(tjs, aes(x = tjs, y = price)) +
  geom_boxplot() +
  coord_flip() +
  ylim(-.25, .25)
p3 &lt;- ggplot(walmart, aes(x = walmart, y = price)) +
  geom_boxplot() +
  coord_flip() +
  ylim(-.25, .25)
p4 &lt;- ggplot(Wegmans, aes(x = Wegmans, y = price)) +
  geom_boxplot() +
  coord_flip() +
  ylim(-.25, .25)
p5 &lt;- ggplot(wholefoods, aes(x = wholefoods, y = price)) +
  geom_boxplot() +
  coord_flip() +
  ylim(-.25, .25)
grid.arrange(p1, p2, p3, p4, p5, ncol=1)
</code></pre>

<p><img src="/img/portfolio/nested.jpeg" alt="caption" /></p>

<p>Pricing looks pretty consistent across regions- Whole Foods is the most expensive, Walmart is the least.</p>

<h3 id="model-comparison-with-loo">Model Comparison with Loo</h3>

<p>Given the consistent pricing across regions, one may ask- is it even worth nesting? After all, there is only at most one store for each supermarket in each region- this makes it pretty difficult to measure within-supermarket variation in each region when there is only one supermarket! This may also explain the errors in sampling.</p>

<p>We will run a non-nested model&hellip;</p>

<pre><code class="language-r">m2 &lt;- stan_glmer(formula = price_norm ~ (1|region_id) + (1|banner_id) - 1 + UPC,
              data = model_data, 
              family = gaussian,
              prior = normal(location = 0, scale = 1, autoscale = FALSE),
              prior_intercept = normal(location = 0, scale = 1, autoscale = FALSE),
              prior_aux = exponential(rate = 1, autoscale = FALSE),
              cores = 4,
              chains = 2,
              iter = 500,
              warmup = 100,
              seed = 1, 
              refresh = 1)
</code></pre>

<p>And a standard regression (still in Stan). The prior in RStanARM is for how much of the variation is explained by the predictors.</p>

<pre><code class="language-r">m1_lm &lt;- stan_lm(formula = price_norm ~ region_id + banner_id + UPC -1,
              data = model_data, 
              prior = R2(0.5),
              cores = 4,
              chains = 4,
              iter = 250,
              warmup = 50,
              seed = 1, 
              refresh = 1,
              control = list(max_treedepth = 15,
                             adapt_delta = 0.95))
</code></pre>

<p><a href="https://mc-stan.org/loo/articles/loo2-example.html">Loo</a> is the recommended package for model comparison. It uses leave-one-out cross validation to compare the expected log density. That sounds complicated, but it&rsquo;s really not that different from looking at the RMSE, except is uses density estimates for each excluded observation on the modeled statistical distribution.</p>

<p>There were some technical difficulties around using Loo- perhaps related to R Studio- but the WAIC comparison (a similar accuracy metric) worked. Results show that the nested model has the lowest elpd score. In other words, the non-nested model fits better. It also doesn&rsquo;t run into the same MCMC errors.</p>

<pre><code class="language-r">m1_waic &lt;- waic(m1, cores = 4)
m1_lm_waic &lt;- waic(m1_lm, cores = 4)
m2_waic &lt;- waic(m2, cores = 4)
###compare
m1_waic[[&quot;estimates&quot;]]
m1_lm_waic[[&quot;estimates&quot;]]
m2_waic[[&quot;estimates&quot;]]
</code></pre>

<pre><code>&gt; m1_waic[[&quot;estimates&quot;]]
             Estimate       SE
elpd_waic  10583.3745 150.8051
p_waic       946.9654  24.8945
waic      -21166.7491 301.6103
&gt; m1_lm_waic[[&quot;estimates&quot;]]
            Estimate       SE
elpd_waic -519766083  7512224
p_waic     519502158  7511770
waic      1039532166 15024447
&gt; m2_waic[[&quot;estimates&quot;]]
            Estimate        SE
elpd_waic   9032.445  528.0411
p_waic      1968.405  379.3835
waic      -18064.890 1056.0823
</code></pre>

<h3 id="posterior-predictive-check">Posterior Predictive Check</h3>

<p>Bayesplot provides the easiest method for posterior predictive checks, which check how well data generated by your model match actual observational responses. Using the non-nested model (now the leading candidate), we can see that our model doesn&rsquo;t fit well at the extremes.</p>

<pre><code class="language-r">pp_check(m2)
</code></pre>

<p><img src="/img/portfolio/m2ppc.jpeg" alt="caption" /></p>

<h3 id="better-priors">Better Priors?</h3>

<p>While the priors for the random effects are likely overwhelmed by the data, it is likely that that priors for the fixed effects- UPC- are constraining the lowest and highest priced items. Why? Recall that there are on average 10 observations for each UPC. In other words, the UPC is much more sensitive to the prior (and also much more likely to effect the price).</p>

<p>To test this, I&rsquo;ll re-run the model with a wider standard deviation of 3.</p>

<pre><code class="language-r">m3 &lt;- stan_glmer(formula = price_norm ~ (1|region_id) + (1|banner_id) - 1 + UPC,
              data = model_data, 
              family = gaussian,
              prior = normal(location = 0, scale = 3, autoscale = FALSE),
              prior_intercept = normal(location = 0, scale = 1, autoscale = FALSE),
              prior_aux = exponential(rate = 1, autoscale = FALSE),
              cores = 4,
              chains = 4,
              iter = 250,
              warmup = 50,
              seed = 1, 
              refresh = 1)
</code></pre>

<pre><code class="language-r">color_scheme_set(&quot;blue&quot;)
pp_check(m3)
</code></pre>

<p><img src="/img/portfolio/m3ppc.jpeg" alt="caption" /></p>

<p>While there is some some discrepancy at the higher end, the model generally fits better along the entire range of y.</p>

<h3 id="conclusions">Conclusions</h3>

<p>A 3 level model without nesting and looser priors offers the best results. The price premiums, given as 50% credibility intervals relative to the pooled mean, are below.</p>

<pre><code class="language-r">sims &lt;- as.matrix(m2)
options(max.print = 100)
#pars &lt;- colnames(sims)[c(1001:1009)] #17 different supermarkets
#posterior_interval(m2, prob = 0.5, pars = pars)
vars &lt;- sims[,c(1001:1009)]
apply(vars, 2, median)
</code></pre>

<pre><code>            b[(Intercept) banner_id:Safeway] 
                                 0.081777177 
        b[(Intercept) banner_id:Trader_Joes] 
                                -0.004313267 
            b[(Intercept) banner_id:Walmart] 
                                -0.090940698 
            b[(Intercept) banner_id:Wegmans] 
                                 0.032037317 
        b[(Intercept) banner_id:Whole_Foods] 
                                 0.199462693 
             b[(Intercept) region_id:Kansas] 
                                -0.050938473 
           b[(Intercept) region_id:New_York] 
                                 0.014482058 
b[(Intercept) region_id:Northern_California] 
                                 0.244150971 
              b[(Intercept) region_id:Texas] 
                                -0.036432502 
</code></pre>

<p>Keep in mind that these effects are linear, so they can be added. For example, Whole Foods in NorCal is the most expensive with a .44 SD price premium, and Walmart in Kansas is the cheapest with a .14 SD discount. Because the model is Bayesian, you can simply combine the samples to estimate other statistics, such as the median or variance.</p>

<p>Github <a href="https://github.com/blakeobeans/Engage3">here</a></p>
         
      </div>
    </div>
  </div>
</div>

          </div>
      </div>
  </div>
  <script src="https://blakeshurtz.github.io/js/jquery.min.js"></script>
<script src="https://blakeshurtz.github.io/js/bootstrap.min.js"></script>
<script src="https://blakeshurtz.github.io/js/jquery.cookie.js"> </script>
<script src="https://blakeshurtz.github.io/js/ekko-lightbox.js"></script>
<script src="https://blakeshurtz.github.io/js/jquery.scrollTo.min.js"></script>
<script src="https://blakeshurtz.github.io/js/masonry.pkgd.min.js"></script>
<script src="https://blakeshurtz.github.io/js/imagesloaded.pkgd.min.js"></script>
<script src="https://blakeshurtz.github.io/js/owl.carousel.min.js"></script>
<script src="https://blakeshurtz.github.io/js/front.js"></script>



</body>
</html>
